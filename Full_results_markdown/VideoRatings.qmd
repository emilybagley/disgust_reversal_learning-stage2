---
title: "Video ratings"
format: gfm
fig-format: jpeg
---

<p>This file contains all the analyses for the video ratings task.</p>
<p>During this task, participants rated the valence, arousal, fear and disgust of 10 videos from Cowen and Keltner (2017). This was done <b>both before and after</b> the reversal learning task.</p>
<p>For each participant, the 'best' pair of fear and disgust videos (see paper for equation used to determine the 'best' pair) was selected prior to the reversal learning task. This pair were then used as punishments in the reversal learning task for the fear and disgust feedback-type blocks.</p>
<p> Analyses here <b>only look at the individually selected video pair</b> for each participant.</p>
<br>
<p>Additionally, after the points block (which doesn't use the Cowen and Keltner videos), each participant was asked to rate the valence, arousal, fear and disgust they felt when they lost points.</p>
<p>Analysis of these responses is also detailed here.</p>
<br>
<p>This notebook contains</p>
<p>
* Analysis of ratings of the selected Cowen and Keltner videos to identify any differences in valence, arousal and habituation between the two stimulus types (models A and B).
* Analysis of ratings of the selected Cowen and Keltner videos to validate that fear and disgust was sucessfully induced (models C and D)
* Analysis of the points ratings (in comparison to timepoint 1 of the selected videos) to assess how the points feedback differed from the fear and disgust feedback
* Visualisation of these results
</p>

<br>
<h3>Step 1: load in packages and data</h3>
```{python}
#| label: Python packages
#| echo: true
#| code-fold: true
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import scipy.stats as stats
import jsonlines
from functools import reduce
import statistics
import scipy.stats
import seaborn as sns
import math
import os
import json
import ast
import matplotlib.patches as mpatches
import statsmodels.api as sm
import statsmodels.formula.api as smf
from numpy import std, mean, sqrt
import warnings
warnings.simplefilter(action='ignore', category=FutureWarning)

chosen_stim_df = pd.read_csv("U:/Documents/Disgust learning project/github/disgust_reversal_learning-final/csvs/chosen_stim_excluded.csv")
chosen_stim_df.drop('Unnamed: 0', axis="columns", inplace=True)
```

<h3>Step 2: create long-form data frame</h3>
```{python}
#| label: long-form df
#| echo: true
long_chosen_stim_df=pd.DataFrame()
for i in chosen_stim_df.index:
    row=chosen_stim_df.loc[i]
    #timepoint=['unpleasan']
    timepoint_1=pd.DataFrame({
    'participant_no': [row.participant_no],
    'age': [row.prolific_age],
    'sex': [row. prolific_sex],
    'Vid': [str(row['Vid'])],
    'trial_type': [row.trial_type],
    'Valence': [row.unpleasant_1],
    'Arousal': [row.arousing_1],
    'Fear': [row.frightening_1],
    'Disgust': [row.disgusting_1],
    'Timepoint': 1.0
    })
    timepoint_2=pd.DataFrame({
        'participant_no': [row.participant_no],
        'age': [row.prolific_age],
        'sex': [row. prolific_sex],
        'Vid': [str(row['Vid'])],
        'trial_type': [row.trial_type],
        'Valence': [row.unpleasant_2],
        'Arousal': [row.arousing_2],
        'Fear': [row.frightening_2],
        'Disgust': [row.disgusting_2],
        'Timepoint': 2.0
    })
    long_chosen_stim_df_row=pd.concat([timepoint_1, timepoint_2])
    long_chosen_stim_df=pd.concat([long_chosen_stim_df_row, long_chosen_stim_df])
    long_chosen_stim_df=long_chosen_stim_df[long_chosen_stim_df.trial_type!="points"]
```

<h3>Step 3: Assess the valence, arousal, disgust and fear ratings of the fear and disgust videos used in the reversal learning task</h3>
<p> Do this using 4 mixed effects models - testing effect of timepoint and stimulus type on ratings </p>
<p>List of models to run:
<p>
* Model A- 'Valence ~ trial_type*Timepoint'
* Model B- 'Arousal ~ trial_type*Timepoint'
* Model C- 'Disgust ~ trial_type*Timepoint'
* Model D- 'Fear ~ trial_type*Timepoint'
</p>
<br>
<br>

<p><b>MODEL A: VALENCE ~ TRIAL_TYPE*TIMEPOINT</b></p>
<p>In this case, the basic model with a by-participant random slope, but no random intercepts or additional covariates produced the best fit (indexed by BIC scores).</p>
<p>
* This model found an effect of trial-type: disgust videos had a more negative valence than fear (this was <b>counter to prediction</b>)
* It also revealed a trial-type*timepoint interaction: valence ratings for disgust didn't change as much over time relative to fear (i.e., disgust is resistant to habituation).
</p>
```{python}
#| label: Model A
#| echo: true

data=long_chosen_stim_df.reset_index()
data.replace(['disgust', 'fear'], [1.0,2.0], inplace=True)
formula = 'Valence ~ trial_type*Timepoint'

model=smf.mixedlm(formula, data, groups=data['participant_no'], missing='drop', re_formula='~trial_type')
results=model.fit(reml=False)
print(results.summary())
```

```{python}
#| echo: false
FDpvals=pd.DataFrame(columns=['Condition','trial_type', 'Timepoint', 'trial_type:Timepoint'])
FDpvals.loc[0]=['Valence', results.pvalues['trial_type'], results.pvalues['Timepoint'], results.pvalues['trial_type:Timepoint']]
```

<br>
<p><b>MODEL B: AROUSAL ~ TRIAL_TYPE*TIMEPOINT</b></p>
<p>In this case, the basic model with no by-participant random slope, no random intercepts and no additional covariates produced the best fit (indexed by BIC scores).</p>
<p>
* This model found an effect of trial-type: fear videos had were more arousing than disgust (this was <b>counter to prediction</b>)
* There was no trial-type*timepoint interaction (no difference in habituation in the arousal measure)
</p>
```{python}
#| label: Model B
#| echo: true

formula = 'Arousal ~ trial_type*Timepoint'

model=smf.mixedlm(formula, data, groups=data['participant_no'], missing='drop')
results=model.fit(reml=False)
print(results.summary())
```

```{python}
#| echo: false
FDpvals.loc[1]=['Arousal', results.pvalues['trial_type'], results.pvalues['Timepoint'], results.pvalues['trial_type:Timepoint']]
```

<br>
<p><b>MODEL C: DISGUST ~ TRIAL_TYPE*TIMEPOINT</b></p>
<p>In this case, the  model with a by-participant random slope, but no random intercepts and no additional covariates produced the best fit (indexed by BIC scores).</p>
<p>
* This model found an effect of trial-type: disgust videos had were more disgusting than fear (this was <b>as predicted</b>)
* There was an effect of timepoint (all stimuli got less disgusting over time)
* There was a trial-type*timepoint interaction (the disgust ratings for fear and disgust videos changed differentially over time)
</p>
```{python}
#| label: Model C
#| echo: true

formula = 'Disgust ~ trial_type*Timepoint'

model=smf.mixedlm(formula, data, groups=data['participant_no'], missing='drop', re_formula='~trial_type')
results=model.fit(reml=False)
print(results.summary())
```

```{python}
#| echo: false
FDpvals.loc[2]=['Disgust', results.pvalues['trial_type'], results.pvalues['Timepoint'], results.pvalues['trial_type:Timepoint']]
```

<br>
<p><b>MODEL D: FEAR ~ TRIAL_TYPE*TIMEPOINT</b></p>
<p>In this case, the  model with a by-participant random slope, but no random intercepts and no additional covariates produced the best fit (indexed by BIC scores).</p>
<p>
* This model found an effect of trial-type: disgust videos had were more disgusting than fear (this was <b>as predicted</b>)
* There was an effect of timepoint (all stimuli got less disgusting over time)
* There was a trial-type*timepoint interaction (the disgust ratings for fear and disgust videos changed differentially over time)
</p>
```{python}
#| label: Model D
#| echo: true

formula = 'Fear ~ trial_type*Timepoint'

model=smf.mixedlm(formula, data, groups=data['participant_no'], missing='drop', re_formula='~trial_type')
results=model.fit(reml=False)
print(results.summary())
```

```{python}
#| echo: false
FDpvals.loc[3]=['Fear', results.pvalues['trial_type'], results.pvalues['Timepoint'], results.pvalues['trial_type:Timepoint']]
FDpvals.to_csv('videoRating_pvals_fearDisgust.csv', index=False)
```

<h3>Step 4: check how points-based feedback differed from disgust and fear-based feedback</h3>
<p> Doing this using 4 mixed effects models - testing the effect of stimulus type on ratings </p>
<p>List of models to run:
<p>
* Model A- 'Valence ~ trial_type'
* Model B- 'Arousal ~ trial_type'
* Model C- 'Disgust ~ trial_type'
* Model D- 'Fear ~ trial_type'
</p>
<p>NB there is only timepoint 1 of fear and disgust ratings are included in this model (as points rating only has one timepoint).</p>

<br>
<br>
<p><b>MODEL E: VALENCE ~ TRIAL_TYPE</b></p>
<p>In this case, the basic model with no by-participant random slope,  no random intercepts but with sex added as a covariate produced the best fit (indexed by BIC scores).</p>
* This model found an effect of trial-type: disgust videos had a more negative valence than points (<b>as predicted</b>)
* But there was <b>no predicted difference</b> in valence between points and fear
* There was also a significant negative effect of age
<p></p>
```{python}
#| label: Model E
#| echo: true

data=chosen_stim_df[['participant_no', 'trial_type', 'unpleasant_1', 'arousing_1', 'disgusting_1', 'frightening_1', 'Vid', 'prolific_age', 'prolific_sex']]
data=data.replace(['points'], ['apoints']) ##makes comparison condition points

formula = 'unpleasant_1~trial_type+prolific_sex'

model=smf.mixedlm(formula, data, groups=data['participant_no'], missing='drop')
results=model.fit(reml=False)
print(results.summary())
```

```{python}
#| echo: false
FDPpvals=pd.DataFrame(columns=['Condition','trial_type[T.disgust]', 'trial_type[T.fear]'])
FDPpvals.loc[0]=['Valence', results.pvalues['trial_type[T.disgust]'], results.pvalues['trial_type[T.fear]']]
```

<p>The effects remain when the sex covariate is removed</p>
```{python}
#| label: Model E no covariates
#| echo: true
formula = 'unpleasant_1~trial_type'

model=smf.mixedlm(formula, data, groups=data['participant_no'], missing='drop')
results=model.fit(reml=False)
print(results.summary())
```

<br>
<br>
<p><b>MODEL F: AROUSAL ~ TRIAL_TYPE</b></p>
<p>In this case, the basic model with no by-participant random slope,  no random intercepts and no additional covariates produced the best fit (indexed by BIC scores).</p>
<p>
* This model found an effect of trial-type: fear videos were more arousing than points (<b>as predicted</b>)
* But there was <b>no predicted difference</b> in arousal between points and disgust
</p>
```{python}
#| label: Model F
#| echo: true

formula = 'arousing_1~trial_type'

model=smf.mixedlm(formula, data, groups=data['participant_no'], missing='drop')
results=model.fit(reml=False)
print(results.summary())
```

```{python}
#| echo: false
FDPpvals.loc[1]=['Arousal', results.pvalues['trial_type[T.disgust]'], results.pvalues['trial_type[T.fear]']]
```

<p><b>MODEL G: DISGUST ~ TRIAL_TYPE</b></p>
<p>In this case, the basic model with no by-participant random slope,  no random intercepts and age as a covariate produced the best fit (indexed by BIC scores).</p>
<p>
* This model found an effect of trial-type: disgust videos were more disgusting than losing points (<b>as predicted</b>)
* Fear videos, perhaps surprisingly, were significantly <b>less</b> disgusting than losing points
* There was also a significant negative effect of age
</p>
```{python}
#| label: Model G
#| echo: true

formula = 'disgusting_1~trial_type+prolific_age'

model=smf.mixedlm(formula, data, groups=data['participant_no'], missing='drop')
results=model.fit(reml=False)
print(results.summary())
```

```{python}
#| echo: false
FDPpvals.loc[2]=['Disgust', results.pvalues['trial_type[T.disgust]'], results.pvalues['trial_type[T.fear]']]
```

<p>The effects are unchanged when the age covariate is removed</p>
```{python}
#| label: Model G no covariate
#| echo: true

formula = 'disgusting_1~trial_type'

model=smf.mixedlm(formula, data, groups=data['participant_no'], missing='drop')
results=model.fit(reml=False)
print(results.summary())
```

<p><b>MODEL H: FEAR ~ TRIAL_TYPE</b></p>
<p>In this case, the basic model with no by-participant random slope,  no random intercepts and age as a covariate produced the best fit (indexed by BIC scores).</p>
<p>
* This model found an effect of trial-type: fear videos were more frightening than losing points (<b>as predicted</b>)
* Disgust videos, perhaps surprisingly (but mirroring results from model H), were significantly <b>less</b> frightening than losing points
* There was also a significant negative effect of age
</p>
```{python}
#| label: Model H
#| echo: true

formula = 'frightening_1~trial_type+prolific_age'

model=smf.mixedlm(formula, data, groups=data['participant_no'], missing='drop')
results=model.fit(reml=False)
print(results.summary())
```

```{python}
#| echo: false
FDPpvals.loc[3]=['Fear', results.pvalues['trial_type[T.disgust]'], results.pvalues['trial_type[T.fear]']]
FDPpvals.to_csv('videoRating_pvals_points.csv', index=False)
```

<p>The effects are unchanged when the age covariate is removed</p>
```{python}
#| label: Model H no covariate
#| echo: true

formula = 'frightening_1~trial_type'

model=smf.mixedlm(formula, data, groups=data['participant_no'], missing='drop')
results=model.fit(reml=False)
print(results.summary())
```

<h3>Conclusions</h3>
<p>Results from these models tells us:</p>
<p>
* The stimulus selection procedure was unable to produce perfectly matched fear and disgust videos (with disgust videos being marginally more negatively valenced and fear videos being more arousing).
* There was a difference in habituation between fear and disgust (fear habituated less than disgust), which is in-line with previous literature.
* Fear and disgust videos reliably induced the emotions of fear and disgust (with fear videos producing much higher fear ratings and vice versa).
* The 'loss' feedback type (from the points conditions) was more similar to the emotional learning conditions than expected. It did not differ from fear in terms of valence and did not differ from disgust in terms of arousal.
* The 'loss' feedback type was, however, very different to the emotional conditions in terms of fear and disgust ratings. 
</p>